from picamera2 import Picamera2
import cv2
from ultralytics import YOLO
import pyttsx3
import time

# Initialize TTS engine
engine = pyttsx3.init()
engine.setProperty('rate', 150)

# Load YOLOv8 model
model = YOLO("yolov8n.pt")

# Start Pi Camera
picam2 = Picamera2()
picam2.configure(picam2.create_preview_configuration(main={"format": "RGB888", "size": (640, 480)}))
picam2.start()
time.sleep(2)  # allow camera to warm up

print("Smart Assistant is ready. Press Enter to detect an object or Ctrl+C to exit.")

def detect_and_speak():
    frame = picam2.capture_array()
    results = model(frame)
    names = results[0].names
    boxes = results[0].boxes

    if boxes.shape[0] > 0:
        top_box = boxes[0]
        cls_id = int(top_box.cls[0])
        label = names[cls_id]
        print(f"Detected: {label}")

        coords = top_box.xyxy[0].cpu().numpy().astype(int)
        x1, y1, x2, y2 = coords
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX,
                    0.9, (0, 255, 0), 2)

        engine.say(f"This is a {label}")
        engine.runAndWait()
    else:
        print("No object detected.")
        engine.say("I can't see anything clearly")
        engine.runAndWait()

    cv2.imshow("Detected Object", frame)
    cv2.waitKey(3000)
    cv2.destroyAllWindows()

# Main loop
try:
    while True:
        input("\nPress Enter to capture...")
        detect_and_speak()
except KeyboardInterrupt:
    print("\nExiting...")
finally:
    picam2.stop()
    cv2.destroyAllWindows()