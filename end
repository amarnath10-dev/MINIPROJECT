from picamera2 import Picamera2
import cv2
from ultralytics import YOLO
import pyttsx3
import time

# Initialize text-to-speech engine
engine = pyttsx3.init()
engine.setProperty('rate', 150)

# Load YOLOv8 (nano model recommended for Raspberry Pi)
model = YOLO("yolov8n.pt")

# Initialize and start the Pi Camera
picam2 = Picamera2()
picam2.configure(picam2.create_preview_configuration(main={"format": "RGB888", "size": (640, 480)}))
picam2.start()

# Short delay to let camera warm up
time.sleep(2)

# Capture a single frame
frame = picam2.capture_array()

# Run YOLO detection
results = model(frame)
names = results[0].names
boxes = results[0].boxes

# Process results
if boxes.shape[0] > 0:
    top_box = boxes[0]
    cls_id = int(top_box.cls[0])
    label = names[cls_id]
    print(f"Detected: {label}")

    # Draw bounding box
    coords = top_box.xyxy[0].cpu().numpy().astype(int)
    x1, y1, x2, y2 = coords
    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
    cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX,
                0.9, (0, 255, 0), 2)

    # Speak detected object
    engine.say(f"This is a {label}")
    engine.runAndWait()
else:
    print("No object detected.")
    engine.say("I can't see anything clearly")
    engine.runAndWait()

# Show result
cv2.imshow("Detected Object", frame)
cv2.waitKey(3000)
cv2.destroyAllWindows()
picam2.stop()