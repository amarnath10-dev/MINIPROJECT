from picamera2 import Picamera2
import cv2
from ultralytics import YOLO
import pyttsx3
import time

# Initialize TTS engine
engine = pyttsx3.init()
engine.setProperty('rate', 150)

# Load YOLOv8 model
model = YOLO("yolov8n.pt")

# Start Pi Camera
picam2 = Picamera2()
picam2.configure(picam2.create_preview_configuration(main={"format": "RGB888", "size": (640, 480)}))
picam2.start()
time.sleep(2)  # allow camera to warm up

print("Smart Assistant is ready. Press Enter to detect an object or Ctrl+C to exit.")

def detect_and_speak():
    frame = picam2.capture_array()
    results = model(frame)
    names = results[0].names
    boxes = results[0].boxes

    if boxes.shape[0] > 0:
        top_box = boxes[0]
        conf_score = float(top_box.conf[0])
        if conf_score >= 0.90:
            cls_id = int(top_box.cls[0])
            label = names[cls_id]
            print(f"Detected: {label} (Confidence: {conf_score*100:.2f}%)")

            coords = top_box.xyxy[0].cpu().numpy().astype(int)
            x1, y1, x2, y2 = coords
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, f"{label} ({conf_score*100:.1f}%)", (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

            engine.say(f"This is a {label}")
            engine.runAndWait()
        else:
            print(f"Low confidence: {conf_score*100:.2f}%. Skipping.")
            engine.say("I'm not confident enough to say.")
            engine.runAndWait()
    else:
        print("No object detected.")
        engine.say("I can't see anything clearly")
        engine.runAndWait()

    cv2.imshow("Detected Object", frame)
    cv2.waitKey(3000)
    cv2.destroyAllWindows()

# Main loop
try:
    while True:
        input("\nPress Enter to capture...")
        detect_and_speak()
except KeyboardInterrupt:
    print("\nExiting...")
finally:
    picam2.stop()
    cv2.destroyAllWindows()